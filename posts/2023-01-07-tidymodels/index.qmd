---
title: "Machine Learning with tidymodels"
author: "สิวะโชติ ศรีสุทธิยากร"
date: "2023-01-06"
categories: [machine learning, R, tidymodels]
toc: true
code-fold: false
code-line-numbers: true
code-tools: 
  source: true
---

![](images/image-670677648.png){width="20%"}

```{r echo=F}
set.seed(123)
```

อ้างอิง

-   <https://www.tmwr.org/index.html>

# Tidymodels

tidymodel เป็น framework ที่ถูกพัฒนาขึ้นเพื่อสนับสนุนการสร้าง machine learning model ในโปรแกรม R ภายใต้ framework นี้ประกอบด้วย package หลายตัว โดยที่แต่ละตัวที่หน้าที่สำหรับทำงานในส่วนต่าง ๆ ภายใต้กระบวนการพัฒนา โมเดล machine learning แผนภาพด้านล่างแสดง framwork ของ tidymodels ดังกล่าว ซึ่งจะเห็นว่าครอบคลุมกระบวนการพัฒนา machine learning model ทั้งหมด

![](images/image-1940323784.png)

-   **package-rsample** ใช้ในงาน resampling ข้อมูล เช่นการสร้าง training/validation/test dataset การสร้าง cross-validation dataset หรือการสร้าง bootstrape dataset

-   **package-recipes** ใช้แปลง/แก้ปัญหาที่เกิดขึ้นในข้อมูลของตัวแปรที่ใช้ในการพัฒนาโมเดล ขั้นตอนนี้เรียกว่า feature engineering

-   **package-parsnip** ใช้ fit machine learning กับข้อมูล

-   **package-Tune** และ **package-dials** มีฟังก์ชันที่อำนวยความสะดวกในการ fine tune hyperparameter ของโมเดลเพื่อเพิ่มประสิทธิภาพการทำนายของโมเดลให้สูงที่สุด

-   **package-yardstick** มีฟังก์ชันของ metric ที่ใช้ประเมินประสิทธิภาพของโมเดลทำนาย

tidymodels ถูกพัฒนาขึ้นโดยได้รับการออกแบบให้สามารถทำซ้ำกระบวนการพัฒนาโมเดลได้ง่าย โดยใช้ไวยกรณ์ของภาษาในลักษณะเดียวกัน และถูกออกแบบโดยเน้นใช้กับ supervised learning เป็นหลัก

ผู้ใช้งานไม่จำเป็นต้องติดตั้งทุก package ในข้างต้นด้วยตนเอง แต่ติดตั้งเพียง package-tidymodels ก็สามารถใช้งานทุก package ภายใต้ framework ดังกล่าวได้แล้ว โดยการพิมพ์คำสั่งต่อไปนี้

```{r eval=F}
install.packages("tidymodels") # ดาวน์โหลดและติดตั้ง tidymodels
library(tidymodels) # เรียกใช้ tidymodels
```

```{r echo=F}
library(tidymodels)
```

# ประเภทของ supervised learning

supervised learning อาจจำแนกได้เป็นสองประเภท ได้แก่ regression และ classification ความแตกต่างของ supervised learning ทั้งสองอยู่ที่ตัวแปรตามที่ต้องการทำนายค่าเป็นตัวแปรแบบเชิงปริมาณ หรือแบบจัดประเภท โดย regression model จะใช้กับตัวแปรตามแบบเชิงปริมาณ ส่วน classification model จะใช้กับตัวแปรตามแบบจัดประเภท

# Bias and Variance

การวัดประสิทธิภาพของโมเดลทำนายอาจพิจารณาจากความคลาดเคลื่อนสองตัวได้แก่ ความลำเอียง (biased) และความแปรปรวน (variance) ความลำเอียงเป็นความคลาดเคลื่อนระหว่างค่าทำนายที่ได้จากโมเดลกับค่าสังเกตจริงของชุดข้อมูลฝึกหัดที่ใช้สอนโมเดล ส่วนความแปรปรวนเป็นความคลาดเคลื่อนระหว่างค่าทำนายของโมเดลกับค่าสังเกตจริงในชุดข้อมูลทดสอบ

โมเดลทำนายที่มีความลำเอียงสูงมีแนวโน้มที่จะเป็น underfitting model ในขณะที่โมเดลทำนายที่มีความแปรปรวนสูงมีแนวโน้มจะเป็น overfitting model รูปด้านล่างแสดงลักษณะของโมเดลทั้งสอง

![](images/image-144476153.png)

-   Underfiting model เป็นโมเดลที่ไม่สามารถเรียนรู้ความสัมพันธ์ของข้อมูลได้ดีพอ ซึ่งจากรูปข้างต้นจะเห็นว่าความสัมพันธ์ในชุดข้อมูลที่นำมาให้โมเดลเรียนรู้นั้นมีลักษณะเป็นเส้นโค้ง แต่โมเดลสามารถเรียนรู้ได้เฉพาะส่วนที่เป็นแนวโน้มเชิงเส้นตรงของความสัมพันธ์เท่านั้น โมเดลจึงมีความลำเอียงไปจากข้อมูลอยู่มาก

-   Overfitting model เป็นโมเดลที่สามารถเรียนรู้ความสัมพันธ์ของข้อมูลได้เป็นอย่างดี ดังตัวอย่างในรูปทางขวามือสุด อย่างไรก็ตามโมเดลดังกล่าวจะมีความยืดหยุ่นในการทำนายค่าสังเกตหรือข้อมูลอื่นที่อยู่นอกเหนือข้อมูลที่นำมาให้โมเดลเรียนรู้ ทำให้เกิดความคลาดเคลื่อนในการทำนายสูงเมื่อนำไปใช้งานในกรณีทั่วไป (มีความแปรปรวนสูง)

ในเชิงอุดมคติ ผู้วิเคราะห์ต้องการให้ความคลาดเคลื่อนทั้งส่วนที่เป็นความลำเอียง และความแปรปรวนนั้น มีความต่ำที่สุดเท่าที่จะสามารถต่ำได้ อย่างไรก็ตามความคลาดเคลื่อนทั้งสองนั้นไม่สามารถทำได้ต่ำที่สุดพร้อมกันได้ รูปด้านล่างแสดงความสัมพันธ์ระหว่างความลำเอียง และความแปรปรวน ซึ่งจะเห็นว่ามีการแปรผกผันซึ่งกันและกัน วัตถุประสงค์ของการพัฒนาโมเดลจึงเป็นการหาจุดที่ดีที่สุดที่ทำให้ความคลาดเคลื่อนทั้งสองอยู่ในจุดที่ต่ำที่สุดเท่าที่จะเป็นไปได้

![](images/image-1953352967.png)

# Data resampling

จาก concept ข้างต้น การตรวจสอบ error ของโมเดลจึงควรมีการตรวจสอบ error ในการทำนายข้อมูลที่นำมาให้โมเดลเรียนรู้ และ error ในการทำนายชุดข้อมูลอื่น ๆ ที่โมเดลไม่ได้เรียนรู้แต่อยู่ภายใต้ประชากรหรือกลุ่มเป้าหมายเดียวกันด้วย ทั้งนี้เพื่อทำให้ผู้วิเคราะห์สามารถวิเคราะห์ error ทั้งสองส่วนได้ และสามารถพัฒนาโมเดลทำนายที่มีความ fit กับข้อมูลพอดี

การดำเนินการที่ควรทำเป็นอย่างน้อยคือการแบ่งชุดข้อมูลที่จะใช้สำหรับพัฒนาโมเดลออกเป็นสองส่วน ส่วนแรกเรียกว่า ชุดข้อมูลฝึกหัด (training dataset) และส่วนที่สองเรียกว่า ชุดข้อมูลทดสอบ (test dataset) โดยที่ training dataset จะใช้เป็นชุดข้อมูลที่ให้อัลกอริทึมเรียนรู้ซึ่งจะให้ผลผลิตเป็นโมเดลทำนาย เขียนแทนด้วย $\hat{f}(X)$ มีความคลาดเคลื่อนภายใน training dataset ต่ำที่สุด (bias ต่ำที่สุด) ในขั้นตอนนี้การเรียนรู้ในส่วนนี้ประกอบด้วยการทำ feature engineering และการ modelling ซึ่งมักมีอัลกอริทึมหลายตัวที่นำมาทดลองเรียนรู้ การพิจารณาว่าอัลกอริทึมใดเหมาะที่จะนำไปใช้งานใรกรณีทั่วไปมากที่สุด จะพิจารณาจากความคลาดเคลื่อนในการทำนายของ $\hat{f}(X)$ ภายใต้ test data

![](images/image-2024899854.png){fig-align="center" width="70%"}

ในเชิงปฏิบัติการแบ่งส่วนข้อมูลออกเป็น training และ test data ไม่ได้มีอัตราส่วนที่แน่นอนทั้งนี้ขึ้นอยู่กับว่าชุดข้อมูลต้นฉบับที่นำมาวิเคราะห์มีขนาดใหญ่/เล็กมากน้อยเพียงใด ideal คือเราต้องการชุดข้อมูล training data ที่ใหญ่เพียงพอจะทำให้อัลกอริทึมสามารถเรียนรู้ความสัมพันธ์ระหว่างข้อมูลได้อย่างครบถ้วน ครอบคลุม และต้องการ test data ที่มีความเป็นตัวแทนกลุ่มเป้าหมาย เพื่อมั่นใจได้ว่าผลการประมาณค่าความคลาดเคลื่อนจะสะท้อนประสิทธิภาพของโมเดลภายในกลุ่มเป้าหมายได้อย่างแม่นยำ อัตราส่วนที่มักใช้กันเช่น 80 : 20, 75 : 25, 60 : 40 หรือ 50 : 50 เป็นต้น การแบ่งส่วนข้อมูลดังกล่าวอาจทำได้สองวิธีการ วิธีการแรกคือการแบ่งด้วยการสุ่มอย่างง่าย (simple random sampling) และวิธีการที่สองคือการแบ่งด้วนการสุ่มแบบชั้นภูมิ (stratified random sampling)

## ชุดข้อมูล `mpg`

ชุดข้อมูลที่ใช้เป็นตัวอย่างจะใช้ dataset `mpg` ของ R ซึ่งถูกติดต้ังมาพร้อมกับการติดตั้งโปรแกรม R อยู่แล้ว ผู้วิเคราะห์สามารถเรียกดูข้อมูลภายใต้ชุดข้อมูล `mpg` ได้โดยพิมพ์คำสั่งต่อไปนี้

```{r}
head(mpg)
glimpse(mpg)
```

จากผลการสำรวจข้างต้นจะเห็นว่าชุดข้อมูล `mpg` ประกอบด้วยข้อมูลเกี่ยวกับรถยนต์ โดยมีตัวแปร (หรือ features) ทั้งหมด 11 ตัว และมีหน่วยข้อมูล (หรือ instance) จำนวน 234 หน่วยข้อมูล ในตัวอย่างนี้กำหนดให้ตัวแปรตามท่ีต้องการทำนายคือ `hwy` (highway fuel efficiency in miles per gallon) ซึ่งเป็นประสิทธิภาพในด้านการประหยัดพลังงานของรถยนต์แต่ละคัน

## Simple random sampling

การแบ่งด้วย simple random sampling เป็นการแบ่งโดยสุ่มข้อมูลตามจำนวนที่กำหนดออกมาเป็นชุดข้อมูล training dataset หรือ test dataset โดยการสุ่มดังกล่าวมีข้อสมมุติว่าหน่วยข้อมูลทุกหน่อยในชุดข้อมูลต้นฉบับมีโอกาสที่จะถูกสุ่มขึ้นมาเท่ากันทั้งหมด การแบ่งข้อมูลด้วยวิธีการนี้ใน R สามารถทำได้หลายวิธี แต่ในบทความนี้จะใช้วิธีที่อยู่ภายใต้ framework ของ tidymodels โดยใช้ฟังก์ชัน [`initial_split()`](https://rsample.tidymodels.org/reference/initial_split.html)

ฟังก์ชันดังกล่าวใช้สำหรับสร้างกรอบการแบ่งข้อมูลด้วยการสุ่มอย่างง่าย ฟังก์ชันดังกล่าวมีอาร์กิวเมนท์ที่สำคัญได้แก่ `data` สำหรับระบุชุดข้อมูลแบบ data.frame ที่ต้องการแบ่ง และ `prop` ใช้ระบุสัดส่วนของ training dataset (เช่น 0.75, 0.8 เป็นต้น) เมื่อสร้างกรอบการแบ่งข้อมูลแล้วส่งผ่านผลลัพธ์ของ `initial_split()` ไปยังฟังก์ชัน `training()` และ `testing()` เพื่อสร้างชุดข้อมูล training และ test dataset ต่อไปนี้ ตัวอย่างด้านข้างแสดงการเขียนคำสั่งตามขั้นตอนการดำเนินงานดังที่กล่าวมา

```{r}
mpg_split1 <- initial_split(data = mpg, prop = 0.75)
mpg_split1
```

ผลลัพธ์ในข้างต้นแสดงให้เห็นว่าฟังก์ชัน `initial_split()` สร้างกรอบการแบ่งข้อมูล โดยกำหนดให้ training dataset มีจำนวน 175 หน่วยข้อมูล และ test dataset มีจำนวน 59 หน่วยข้อมูล

```{r}
train_srs <- mpg_split1 %>% training()
test_srs <- mpg_split1 %>% testing()
```

## Stratified random sampling

วัตถุประสงค์หลักของการพัฒนา machine learning model คือการหาโมเดลที่สามารถทำนายตัวแปรตามได้อย่างมีประสิทธิภาพ ภายในชุดข้อมูล training และ test dataset จึงควรมีหน่วยข้อมูลที่มีค่าของตัวแปรตามครอบคลุมค่าที่เป็นไปได้ของตัวแปรตามทั้งหมด วิธีการสุ่มแบบชั้นภูมิเป็นวิธีการที่ถูกนำมาใช้เพื่อช่วยรับประกันว่าชุดข้อมูล training และ test จะมีหน่วยข้อมูลที่ครอบคลุมค่าที่เป็นไปได้ของตัวแปรตามได้ครบหรือใกล้เคียงกันมากที่สุด

การแบ่งชุดข้อมูลด้วยการสุ่มแบบชั้นภูมิสามารถทำได้ด้วยฟังก์ชัน `initial_split()` เช่นเดียวกัน แต่จะต้องมีการระบุอาร์กิวเมนท์ `strata` เป็นตัวแปรเกณฑ์ที่จะใช้แบ่งชั้นภูมิซึ่งมักใช้เป็นตัวแปรตามของโมเดลด้วยเหตุผลดังที่กล่าวมาแล้ว นอกจากนี้ยังมีอาร์กิวเมนท์ `breaks` ที่ใช้ระบุจำนวนอันตรภาคชั้นที่จะใช้แบ่งชั้นภูมิของตัวแปรตามในกรณีที่ตัวแปรตามเป็นเชิงปริมาณ ค่าเริ่มต้นของอาร์กิวเมนท์นี้กำหนดให้ `breaks = 4`

ตัวอย่างต่อไปนี้แสดงการแบ่งชุดข้อมูล training และ test โดยใช้การสุ่มแบบชั้นภูมิ

```{r}
mpg_split2 <- initial_split(data = mpg, 
                           prop = 0.75,
                           strata = "hwy",
                           breaks = 8)

train_str <- training(mpg_split2)
test_str <- testing(mpg_split2)
```

รูปด้านล่างแสดงการเปรียบเทียบการแจกแจงของตัวแปรตามระหว่างชุดข้อมูลต้นฉบับ และชุดข้อมูล training และ test ที่แบ่งด้วยวิธีการสุ่มอย่างง่าย และสุ่มแบบชั้นภูมิ

```{r echo=FALSE, message=F, warning=F, fig.height=6}
library(ggplot2)
library(gridExtra)

total<-mpg%>%ggplot()+geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  theme_minimal()+
  ggtitle("original dataset")

p1<-train_srs%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  theme_minimal()+
  ggtitle("training dataset (SRS)")+
  theme(panel.grid.minor = element_blank())


p2<-train_str%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  ggtitle("training dataset (STR)")+
  theme(panel.grid.minor = element_blank())

p3<-test_srs%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  scale_y_continuous(limits=c(0,13))+
  theme_minimal()+
  ggtitle("test dataset (SRS)")

p4<-test_str%>%ggplot()+
  geom_histogram(aes(x=hwy))+
  scale_x_continuous(limits=c(0,50))+
  scale_y_continuous(limits=c(0,13))+
  ggtitle("test dataset (STR)")+
  theme(panel.grid.minor = element_blank())

grid.arrange(total, p1 , p2, p3, p4 , layout_matrix=rbind(c(1,1),c(2,3),c(4,5)))
```

# Linear Regression with tidymodels

หัวข้อนี้จะแสดงการพัฒนาโมเดลทำนายด้วยอัลกอริทึม linear regression โดยใช้ [Tidymodels] ที่ได้กล่าวไปในข้างต้น การ train ให้อัลกอริทึม linear regression สามารถเรียนรู้ความสัมพันธ์ระหว่างตัวแปรตาม `hyw` กับตัวแปรทำนายต่าง ๆ ในชุดข้อมูลจะดำเนินงานด้วย package parsnip และการประเมินประสิทธิภาพในการทำนายของโมเดลที่พัฒนาขึ้นจะใช้ evaluation metric ที่อยู่ภายใต้ package-yardstick

โมเดลการวิเคราะห์การถดถอยเชิงเส้น (linear regression) เป็นโมเดลเชิงสถิติ (statistical model) ที่ใช้สำหรับทำนายแนวโน้มค่าสังเกตของตัวแปรตามที่ไม่ทราบค่าโดยอิงกับค่าสังเกตของตัวแปรอิสระที่ทราบค่า การเรียนรู้ของ linear regression จะพยายามสร้างสมการเส้นตรงที่ดีที่สุด (best linear equation) ที่สามารถใช้เป็นตัวแทนความสัมพันธ์ตามธรรมชาติระหว่างตัวแปรตามกับตัวแปรอิสระที่พบในชุดข้อมูล ในเชิงเทคนิคการหาสมการเส้นตรงดังกล่าวจะเป็นการแก้สมการหรือเฟ้นหาค่าของพารามิเตอร์ภายในสมการเส้นตรง ได้แก่ พารามิเตอร์จุดตัดแกน y และพารามิเตอร์ความชัน ที่ทำให้สมการเส้นตรงมีความคลาดเคลื่อนในการทำนายต่ำที่สุด

สมการเส้นตรงดังกล่าวจะถูกใช้เป็นเครื่องมือสำหรับทำนายค่าของตัวแปรตามเมื่อกำหนดค่าสังเกตที่ทราบค่าของตัวแปรอิสระทั้งหมดภายในโมเดล ยกตัวอย่างเช่น จากชุดข้อมูล `mpg` สมมุติว่าผู้วิเคราะห์เลือกให้ตัวแปร `cty` (city fuel efficiency) เป็นตัวแปรอิสระเพียงตัวเดียวที่จะใช้ทำนาย `hwy` กรณีนี้สมการเส้นตรงที่จะใช้ทำนายสามารถเขียนในรูปมาตรฐานได้ดังนี้

$$
hwy=\beta_0+\beta_1cty
$$

โดยที่ $\beta_0, \beta_1$ คือพารามิเตอร์จุดตัดแกน และความชันของสมการ จากรูปด้านล่างจะเห็นว่า การกำหนดค่าพารามิเตอร์ดังกล่าวที่แตกต่างกันจะทำให้ได้ผลลัพธ์เป็นเส้นตรงที่มีจุดตัดแกนและความชันที่แตกต่างกัน ซึ่งมีโดยตรงผลต่อประสิทธิภาพในการทำนาย อัลกอริทึมจะหาค่าพารามิเตอร์ $\beta_0,\beta_1$ที่ดีที่สุด ซึ่งจากรูปจะเห็นว่าเส้นตรงที่น้ำเงินคือเส้นตรงที่มีความสอดคล้องหรือ fit กับข้อมูลมากที่สุดเมื่อเปรียบเทียบกับเส้นตรงอื่น ๆ ภายใต้เส้นตรงทั้งหมดในรูป เส้นตรงสีน้ำเงินจึงเป็นเส้นตรงที่ดีที่สุด สมการเส้นตรงสีน้ำเงินสามารถเขียนได้ดังนี้

$$
\hat{hwy}=1.039 + 1.329cty
$$

```{r echo=F, fig.width=6,fig.height=4, fig.align="center"}
fit<-lm(data = train_str, hwy ~ cty)
train_str%>%ggplot()+
  geom_point(aes(x=cty, y=hwy))+
  theme_minimal()+
  geom_abline(intercept=-10, slope=2, col="grey")+
  geom_abline(intercept=5, slope=1.5, col="grey")+
  geom_abline(intercept=20, slope=0.4, col="grey")+
  geom_abline(intercept=fit$coefficients[1], slope=fit$coefficients[2], col="steelblue")
```

อย่างไรก็ตามในกรณีทั่วไปเส้นตรงที่เป็นไปได้ของแต่ละชุดข้อมูลมีจำนวนนับไม่ถ้วน การหาเส้นตรงที่ดีที่สุดจึงเป็นการหาผ่านอัลกอริทึม โดยอัลกอริทึม linear regression จะหาค่าของค่าพารามิเตอร์ $\beta_0,\beta_1$ ที่ทำให้ฟังก์ชันผลรวมกำลังสอง (sum square errors: SSE) ที่มีต่ำที่สุด ภายใต้สถานการณ์ที่ต้องการใช้ `cty` เป็นตัวแปรเพื่อทำนาย `hyw` สามารถเขียนฟังก์ชัน SSE ได้ดังนี้

$$
SSE = \sum_{i=1}^n(hwy-\hat{hwy})^2=\sum_{i=1}^n(hwy-\beta_0-\beta_1cty)^2
$$

รูปด้านล่างแสดงระนาบของฟังก์ชัน SSE ในแต่ละค่าที่เป็นไปได้ของพารามิเตอร์ $\beta_0,\beta_1$ ซึ่งจะเห็นว่าค่าพารามิเตอร์ที่เหมาะสมเท่านั้นที่จะทำให้ค่า SSE มีค่าต่ำที่สุดได้

```{r message=F, echo=F}
beta0<-seq(0,1,by=0.01)
beta1<-seq(1,2,by=0.01)
beta<-as.matrix(expand.grid(beta0,beta1))

sse<-function(beta)
{
  sse<-sum(mpg$hwy-beta[1]-beta[2]*mpg$cty)^2
  return(sse)
}
apply(beta, MARGIN=1, FUN=sse)->temp

sse_grid<-matrix(temp,nrow=length(beta0), ncol=length(beta1), byrow=TRUE)
rownames(sse_grid)<-beta0
colnames(sse_grid)<-beta1

library(plotly)
p<-plot_ly(z=sse_grid, type="surface", x=beta0, y=beta1)%>%
    layout(scene = list(xaxis=list(title="beta0"),
           yaxis=list(title="beta1"),
           zaxis=list(title="SSE")))%>%
    config(responsive = FALSE, displayModeBar = FALSE)

p
```

## การ fit linear regression ด้วย `parsnip`

คู่มือ package parsnip

-   <https://cran.r-project.org/web/packages/parsnip/parsnip.pdf>

-   <https://cran.r-project.org/web/packages/parsnip/vignettes/parsnip.html>

การ train อัลกอริทึมการเรียนรู้ของเครื่องใน R ที่ยุคเริ่มต้น ผู้วิเคราะห์ต้องทำงานร่วมกับ package หลายตัว ทั้งนี้เป็นเพราะแต่ละ package ใช้สำหรับ fit supervised learning ได้จำกัด ทั้งนี้ package ต่าง ๆ มักมีไวยกรณ์การเขียนคำสั่งที่แตกต่างกัน ทำให้ทำงานได้ยากพอสมควร package parsnip ถูกพัฒนาขึ้นเพื่อแก้ปัญหาดังกล่าว โดยทำหน้าที่เป็น interface ให้ผู้ใช้พิมพ์คำสั่งเพื่อใช้งาน package ของ R ต่าง ๆ ที่เกี่ยวข้องได้ ภายใต้ไวยกรณ์แบบเดียวกันทั้งหมด ซึ่งทำการทำงานง่ายขึ้นอย่างมาก ขั้นตอนการทำงานด้วย parsnip มีดังนี้

1.  เลือกฟังก์ชัน model type ที่จะใช้ เช่น linear regression, K-NN, decision tree หรืออื่น ๆ
2.  เลือก engine ที่จะใช้การประมวลผล engine คือ package ของ R ที่ parsnip จะไปดึงมาเพื่อประมวลผลตามคำสั่ง
3.  กำหนด mode ว่าการทำนายเป็นแบบ regression หรือ classification

รายละเอียดว่าผู้วิเคราะห์สามารถกำหนด model type, engine และ mode แบบใดได้บ้างและต้องกำหนดอย่างไร สามารถศึกษาได้จาก <https://www.tidymodels.org/find/parsnip/> รูปด้านล่างแสดงค้นหาสำหรับอัลกอริทึม linear regression

![](images/image-1216652031.png)

จากผลการค้นหาข้างต้นจะเห็นว่าการ fit linear regression ด้วย parsnip สามารถทำได้ด้วย model type คือ `linear_reg()` เมื่อพิจารณาในคอลัมน์ engine จะเห็นว่าการ fit linear regression มี engine จำนวนมากที่สามารถใช้เพื่อประมาณค่าพารามิเตอร์ของโมเดลได้

ในคู่มือข้างต้นยังมีเครื่องมือให้ค้นหาการกำหนดอาร์กิวเมนท์ของฟังก์ชัน model type ในข้างต้น จากรูปด้านล่างจะเห็นรายละเอียดในการกำหนดอาร์กิวเมนท์ของฟังก์ชัน `linear_reg()` เมื่อกำหนด engine ในลักษณะต่าง ๆ

![](images/image-1295331953.png)

ความหมายของการกำหนดอาร์กิวเมนท์แต่ละค่าสามารถศึกษาได้จากคู่มือของฟังก์ชัน `linear_reg()` ซึ่งสามารถกด hyperlink จากคู่มือข้างต้นเข้าไปศึกษาได้เลย (คู่มือ [`linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html))

เอกสารอ่านเพิ่มเติม

-   <https://rawgit.com/pbiecek/DALEX_docs/master/vignettes/DALEX_and_keras.html>
